{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install torch transformers datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, images_dir, labels_dir, tokenizer, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(images_dir)\n",
        "        self.label_files = os.listdir(labels_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
        "        label_path = os.path.join(self.labels_dir, self.label_files[idx])\n",
        "\n",
        "        # Open image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Load label\n",
        "        with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            label = f.read().strip()\n",
        "\n",
        "        # Tokenize the label text\n",
        "        tokenized_label = self.tokenizer(label, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "        return image, tokenized_label[\"input_ids\"].squeeze(), tokenized_label[\"attention_mask\"].squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AdamW\n",
        "import torch\n",
        "\n",
        "# Load the model\n",
        "model_name = \"stepfun-ai/GOT-OCR2_0\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load dataset\n",
        "train_dataset = OCRDataset(\"/images\", \"/labels\", tokenizer)\n",
        "\n",
        "# DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Fine-tuning loop\n",
        "for epoch in range(3):  # You can adjust the number of epochs\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        images, input_ids, attention_mask = batch\n",
        "        images = images.to(device)\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = outputs.loss\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"fine_tuned_ocr_model\")\n",
        "tokenizer.save_pretrained(\"fine_tuned_ocr_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n6MaV603BhKL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "def extract_mrp_exp_date_(image_file):\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load the pre-trained model and tokenizer\n",
        "    model_name = \"stepfun-ai/GOT-OCR2_0\"\n",
        "    model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "    # Perform OCR on the input image\n",
        "    res = model.chat(tokenizer, image_file, ocr_type='ocr')\n",
        "    text = res  # Adjust based on the structure of your OCR output\n",
        "    print(\"OCR Text:\", text)\n",
        "\n",
        "    # Function to correct common OCR errors\n",
        "    def correct_ocr_errors(text):\n",
        "        text = text.replace(\"O\", \"0\")  # Correct 'O' to '0'\n",
        "        text = text.replace(\"l\", \"1\")  # Correct 'l' to '1'\n",
        "        return text\n",
        "\n",
        "    # Function to handle 'MR PRs.' to 'MRPRs.' and other MRP-related corrections\n",
        "    def convert_to_mrpr(text):\n",
        "        text = text.replace('MR PRs.', 'MRPRs.')\n",
        "        # Use regex to find numbers and combine them like '2 0/-' to '20/-'\n",
        "        match = re.search(r'(\\d)\\s*(0/\\s*-)', text)\n",
        "        if match:\n",
        "            text = text.replace(match.group(0), '20/-')\n",
        "        return text\n",
        "\n",
        "    # Extract the MRP from the text\n",
        "    def extract_mrp(text):\n",
        "        text = convert_to_mrpr(text)\n",
        "        text = correct_ocr_errors(text)\n",
        "        mrp_pattern = r'(?i)(?:mr\\s*r\\s*|mr\\s*prs?\\s*|rs\\.?|â‚¹)\\s*[:\\-]?\\s*([\\d/]+)'\n",
        "        match = re.search(mrp_pattern, text)\n",
        "\n",
        "        if match:\n",
        "            mrp = match.group(1)\n",
        "            corrected_mrp = correct_ocr_errors(mrp)\n",
        "            corrected_mrp = re.sub(r'[^\\d.,]', '', corrected_mrp)\n",
        "            return corrected_mrp\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "    # Preprocess text to normalize date-related keywords and remove noise\n",
        "    def preprocess_text(text):\n",
        "        keywords_map = {\n",
        "            \"EXP\": [\"XP\", \"EX\", \"EXR\", \"Expires\"],\n",
        "            \"MFD\": [\"MFR\", \"MF\", \"MFG\", \"PROD\"]\n",
        "        }\n",
        "        month_map = {\n",
        "            \"JAN\": [\"JAN\", \"JNA\", \"JANUARY\"], \"FEB\": [\"FEB\", \"FEBRUARY\"],\n",
        "            \"MAR\": [\"MAR\", \"MARCH\"], \"APR\": [\"APR\", \"APRL\", \"APRIL\"],\n",
        "            \"MAY\": [\"MAY\", \"MA\"], \"JUN\": [\"JUN\", \"JN\", \"JUNE\"],\n",
        "            \"JUL\": [\"JUL\", \"JLY\", \"JULY\"], \"AUG\": [\"AUG\", \"AG\", \"AUGUST\"],\n",
        "            \"SEP\": [\"SEP\", \"SEPT\", \"SEPTEMBER\"], \"OCT\": [\"OCT\", \"OCTOBER\"],\n",
        "            \"NOV\": [\"NOV\", \"NOVEMBER\"], \"DEC\": [\"DEC\", \"DECM\", \"DECEMBER\"]\n",
        "        }\n",
        "\n",
        "        for correct_word, variations in keywords_map.items():\n",
        "            for variant in variations:\n",
        "                text = re.sub(r'\\b' + variant + r'\\b', correct_word, text, flags=re.IGNORECASE)\n",
        "\n",
        "        for correct_month, variations in month_map.items():\n",
        "            for variant in variations:\n",
        "                text = re.sub(r'\\b' + variant + r'\\b', correct_month, text, flags=re.IGNORECASE)\n",
        "\n",
        "        text = text.upper()\n",
        "        text = re.sub(r'[^A-Z0-9\\s:.-/]', ' ', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    # Function to parse date string into datetime object\n",
        "    def parse_date(date_string):\n",
        "        formats = ['%d/%m/%y', '%d/%m/%Y', '%d-%m-%y', '%d-%m-%Y', '%d %b %Y', '%d %b %y', '%b %d %Y', '%b %d, %Y']\n",
        "        for fmt in formats:\n",
        "            try:\n",
        "                return datetime.strptime(date_string, fmt)\n",
        "            except ValueError:\n",
        "                continue\n",
        "        return None\n",
        "\n",
        "    # Find the most recent date in the text\n",
        "    def find_most_recent_date(text):\n",
        "        preprocessed_text = preprocess_text(text)\n",
        "        print(\"Preprocessed Text for Date Extraction:\", preprocessed_text)\n",
        "\n",
        "        date_pattern = r'\\b(\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{1,2}\\s*[A-Z]{3}\\s*\\d{2,4}|\\b[A-Z]{3,9}\\s*\\d{1,2},?\\s*\\d{4})\\b'\n",
        "        matches = re.findall(date_pattern, preprocessed_text)\n",
        "        print(\"Potential Dates Found:\", matches)\n",
        "\n",
        "        dates = []\n",
        "        for date_str in matches:\n",
        "            parsed_date = parse_date(date_str)\n",
        "            if parsed_date:\n",
        "                dates.append(parsed_date)\n",
        "\n",
        "        if dates:\n",
        "            most_recent_date = max(dates)\n",
        "            return most_recent_date.strftime('%d/%m/%Y')\n",
        "        else:\n",
        "            return \"No valid date found\"\n",
        "\n",
        "    # Extract MRP and find the most recent expiry/manufacture date\n",
        "    extracted_mrp = extract_mrp(text)\n",
        "    most_recent_date = find_most_recent_date(text)\n",
        "\n",
        "    # Output results\n",
        "    if extracted_mrp:\n",
        "        print(\"Extracted MRP: Rs.\", extracted_mrp)\n",
        "    else:\n",
        "        print(\"MRP not found.\")\n",
        "    print(\"Most Recent Date (Expiry/Manufacture):\", most_recent_date)\n",
        "\n",
        "    result = {\n",
        "        \"MRP\": extracted_mrp,\n",
        "        \"Expiry_Date\": most_recent_date\n",
        "    }\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTAXA-GbBsCR",
        "outputId": "832e69b5-9d64-4337-e662-03b03dc931c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: verovio in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install verovio tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL15h-TpCHLG",
        "outputId": "042af901-eaa7-43b5-b3a3-6363b23ab815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ngrok in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
            "Requirement already satisfied: jsonify in /usr/local/lib/python3.10/dist-packages (0.5)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install ngrok flask flask-cors jsonify pyngrok pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnQNHlReCKzi",
        "outputId": "27f2f6b4-e44a-424b-9036-bbdfd6382400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ngrok URL: https://c69b-35-240-158-120.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Oct/2024 19:15:44] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received data: {'key': 'Front packet', 'another_key': 'dsfgs'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Oct/2024 19:16:20] \"POST /webhook/mrpexp HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OCR Text: NET 0 TY.  MFD& USE BY PER PACK B. NO. :  NO. OF SERVES UNTIS AL EP RICE.  MR PRS. 2 O/ ( IN CL. OF ALL TAXES)  489 27109/24&24/02/25 24/ N 2270924 RS. 0.50/ - PER 9 88 08:20\n",
            "Preprocessed Text for Date Extraction: NET 0 TY. MFD USE BY PER PACK B. NO. : NO. OF SERVES UNTIS AL EP RICE. MR PRS. 2 O/ IN CL. OF ALL TAXES 489 27109/24 24/02/25 24/ N 2270924 RS. 0.50/ PER 9 88 08:20\n",
            "Potential Dates Found: ['24/02/25']\n",
            "Extracted MRP: Rs. 20\n",
            "Most Recent Date (Expiry/Manufacture): 24/02/2025\n",
            "{'MRP': 20, 'Expiry_Date': '24/02/2025'}\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request,jsonify\n",
        "from pyngrok import ngrok\n",
        "from flask_cors import CORS  # Import CORS\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Set your ngrok authentication token\n",
        "ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Enable CORS for the app\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/webhook/mrpexp', methods=['POST'])\n",
        "def webhook():\n",
        "    # Get the image from the request\n",
        "    if 'file' not in request.files:\n",
        "        print(\"No image part\", 400)\n",
        "\n",
        "    image_file = request.files['file']\n",
        "\n",
        "    if image_file.filename == '':\n",
        "        print(\"No image selected\", 400)\n",
        "     \n",
        "    # Read the image using PIL\n",
        "    image = Image.open(image_file)\n",
        "    temp_image_path = \"/tmp/temp_image.jpg\"  # Temporary path to store the image\n",
        "    image.save(temp_image_path)\n",
        "\n",
        "    # Extract JSON data from the form\n",
        "    data = request.form.to_dict()\n",
        "    print(\"Received data:\", data)\n",
        "\n",
        "    # Process the image with the product_name function\n",
        "    result = extract_mrp_exp_date_(temp_image_path)  # Ensure product_name is defined\n",
        "\n",
        "    # return result, 200\n",
        "    print(result)\n",
        "\n",
        "    # Return the response from the second server to the client\n",
        "    # if response.status_code == 200:\n",
        "    # else:\n",
        "    #     return \"Error analyzing image on second server\", response.status_code\n",
        "    return jsonify({\"analysis\": result}), 200\n",
        "\n",
        "# Start ngrok\n",
        "ngrok_tunnel = ngrok.connect(5000)\n",
        "print(\"Ngrok URL:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# Run the Flask app\n",
        "app.run(port=5000, debug=True, use_reloader=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBVm8D2pCghJ"
      },
      "outputs": [],
      "source": [
        "#en"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
